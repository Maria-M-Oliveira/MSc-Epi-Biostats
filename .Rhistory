posthocs
install.packages("DescTools", dependencies = TRUE)
install.packages("FSA", dependencies = TRUE)
install.packages("PMCMRplus", dependencies = TRUE)
library(DescTools)
library(DescTools)
library(FSA)
library(PMCMRplus)
m1<-kruskal.test(Médicos ~ NUTS_II, data=Med_BD)
print(m1)
#Dunn's Kruskal-Wallis post-hoc test
posthocs1<-dunnTest(Médicos ~ NUTS_II, data=Med_DB, method="holm")
print(posthocs1)
#Dwass, Steel, Critchlow, Fligner post-hoc test
posthocs2<-dscfAllPairsTest(Médicos ~ NUTS_II, data=dat)
print(posthocs2)
#Perform the Kruskal-Wallis test
m1<-kruskal.test(Médicos ~ NUTS_II, data=Med_BD)
print(m1)
#Dunn's Kruskal-Wallis post-hoc test
posthocs1<-dunnTest(Médicos ~ NUTS_II, data=Med_DB, method="holm")
#Dunn's Kruskal-Wallis post-hoc test
posthocs1<-dunnTest(Médicos ~ NUTS_II, data=Med_BD, method="holm")
print(posthocs1)
#Dwass, Steel, Critchlow, Fligner post-hoc test
posthocs2<-dscfAllPairsTest(Médicos ~ NUTS_II, data=Med_BD)
print(posthocs2)
print(m1)
library(tidyverse)
library(ggplot2)
library(foreign)
#Files
BD <- read.spss("BaseCovid_trabalho4.sav", to.data.frame = TRUE)
View(BD)
# Quiquadrado
cross_age_cases <- xtabs(~BD$total_cases_per_million_10_tercil+BD$median_age_2cat)
cross_age_cases
install.packages("DescTools")
library(DescTools)
df_cross <- as.table(cross_age_cases)
expected <- ExpFreq(df_cross)
View(expected)
# Every value is <5, so assumptions are met
qui <- chisq.test(BD$total_cases_per_million_10_tercil, BD$median_age_2cat)
qui
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(ggplot2)
library(readxl)
library(freqtables)
library(naniar)
library(stats)
library(moments)
asma_miss_analysis <- miss_var_summary(asma) #Returns a tibble of missing values count and percent by variable
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(ggplot2)
library(readxl)
library(freqtables)
library(naniar)
library(stats)
library(moments)
asma <- read_xlsx("Asma_GDH.xlsx")
asma_miss_analysis <- miss_var_summary(asma) #Returns a tibble of missing values count and percent by variable
#quantitativa variables: idade, dias internamento,num procedimentos
age_box_plot <- boxplot(asma$`Idade (anos)`) #No outliers or impossible values
intern_days_box_plot <- boxplot(asma$`Dias de internamento`) #Several outliers and some extreme points that could be indicative of impossible values
procedure_box_plot <- boxplot(asma$`Numero de Procedimentos`) #Several outliers and some extreme points that could be indicative of impossible values
miss_var_summary(asma) #Returns a tibble of missing values count and percent by variable
#quantitativa variables: idade, dias internamento,num procedimentos
age_box_plot <- boxplot(asma$`Idade (anos)`) #No outliers or impossible values
intern_days_box_plot <- boxplot(asma$`Dias de internamento`) #Several outliers and some extreme points that could be indicative of impossible values
procedure_box_plot <- boxplot(asma$`Numero de Procedimentos`) #Several outliers and some extreme points that could be indicative of impossible values
?boxplot
#quantitativa variables: idade, dias internamento,num procedimentos
age_box_plot <- boxplot(asma$`Idade (anos)`,
ylab="Idade (anos)",
main="Boxplot of Partcipant Ages",
col="blue") #No outliers or impossible values
#quantitativa variables: idade, dias internamento,num procedimentos
age_box_plot <- boxplot(asma$`Idade (anos)`,
ylab="Idade (anos)",
main="Boxplot of Partcipant Ages",
col="orange") #No outliers or impossible values
intern_days_box_plot <- boxplot(asma$`Dias de internamento`,
ylab="Hospitalization days",
main="Boxplot of hospitalization days",
col="yellow") #Several outliers and some extreme points that could be indicative of impossible values
procedure_box_plot <- boxplot(asma$`Numero de Procedimentos`,
ylab="Number of procedures",
main="Boxplot of number of procedures",
col="cyan") #Several outliers and some extreme points that could be indicative of impossible values
procedure_box_plot <- boxplot(asma$`Numero de Procedimentos`,
ylab="Number of procedures",
main="Boxplot of number of procedures",
col="cyan",
border="darkblue") #Several outliers and some extreme points that could be indicative of impossible values
miss_var_summary(asma) #Returns a tibble of missing values count and percent by variable
summarize(mean = mean(`Idade (anos)`),
median = median(`Idade (anos)`),
min = min(`Idade (anos)`),
max = max(`Idade (anos)`),
stdev = sd(`Idade (anos)`),
var = stdev^2,
kurt= kurtosis(`Idade (anos)`),
skew = skewness(`Idade (anos)`),
interquart = IQR(`Idade (anos)`))
asma %>% summarize(mean = mean(`Idade (anos)`),
median = median(`Idade (anos)`),
min = min(`Idade (anos)`),
max = max(`Idade (anos)`),
stdev = sd(`Idade (anos)`),
var = stdev^2,
kurt= kurtosis(`Idade (anos)`),
skew = skewness(`Idade (anos)`),
interquart = IQR(`Idade (anos)`))
asma %>% summarize(mean = mean(`Idade (anos)`),
median = median(`Idade (anos)`),
min = min(`Idade (anos)`),
max = max(`Idade (anos)`),
stdev = sd(`Idade (anos)`),
var = stdev^2,
kurt= kurtosis(`Idade (anos)`),
skew = skewness(`Idade (anos)`),
interquart = IQR(`Idade (anos)`))
#quantitativa variables: idade, dias internamento,num procedimentos
age_box_plot <- boxplot(asma$`Idade (anos)`,
ylab="Idade (anos)",
main="Boxplot of Partcipant Ages",
col="orange",
border="brown") #No outliers or impossible values
intern_days_box_plot <- boxplot(asma$`Dias de internamento`,
ylab="Hospitalization days",
main="Boxplot of hospitalization days",
col="yellow",
border="brown") #Several outliers and some extreme points that could be indicative of impossible values
procedure_box_plot <- boxplot(asma$`Numero de Procedimentos`,
ylab="Number of procedures",
main="Boxplot of number of procedures",
col="cyan",
border="darkblue") #Several outliers and some extreme points that could be indicative of impossible values
asma %>%
summarise(n = n(),
mean = mean(`Idade (anos)`, na.rm = TRUE),
sd = sd(`Idade (anos)`, na.rm = TRUE),
stderr = sd/sqrt(n),
LCL = mean - qt(1 - (0.05 / 2), n - 1) * stderr,
UCL = mean + qt(1 - (0.05 / 2), n - 1) * stderr,
median=median(`Idade (anos)`, na.rm = TRUE),
min=min(`Idade (anos)`, na.rm = TRUE),
max=max(`Idade (anos)`, na.rm = TRUE),
IQR=IQR(`Idade (anos)`, na.rm = TRUE),
kurt= kurtosis(`Idade (anos)`),
skew = skewness(`Idade (anos)`))
#quantitativa variables: idade, dias internamento,num procedimentos
age_box_plot <- boxplot(asma$`Idade (anos)`,
ylab="Idade (anos)",
main="Boxplot of Partcipant Ages",
col="orange",
border="brown") #No outliers or impossible values
intern_days_box_plot <- boxplot(asma$`Dias de internamento`,
ylab="Hospitalization days",
main="Boxplot of hospitalization days",
col="yellow",
border="brown") #Several outliers and some extreme points that could be indicative of impossible values
procedure_box_plot <- boxplot(asma$`Numero de Procedimentos`,
ylab="Number of procedures",
main="Boxplot of number of procedures",
col="cyan",
border="darkblue") #Several outliers and some extreme points that could be indicative of impossible values
asma %>%
summarise(n = n(),
mean = mean(`Idade (anos)`, na.rm = TRUE),
sd = sd(`Idade (anos)`, na.rm = TRUE),
stderr = sd/sqrt(n),
LCL = mean - qt(1 - (0.05 / 2), n - 1) * stderr,
UCL = mean + qt(1 - (0.05 / 2), n - 1) * stderr,
median=median(`Idade (anos)`, na.rm = TRUE),
min=min(`Idade (anos)`, na.rm = TRUE),
max=max(`Idade (anos)`, na.rm = TRUE),
IQR=IQR(`Idade (anos)`, na.rm = TRUE),
kurt= kurtosis(`Idade (anos)`),
skew = skewness(`Idade (anos)`))
#quantitativa variables: idade, dias internamento,num procedimentos
age_box_plot <- boxplot(asma$`Idade (anos)`,
ylab="Idade (anos)",
main="Boxplot of Partcipant Ages",
col="orange",
border="brown") #No outliers or impossible values
```
### Transform the variable "Idade (anos)" in a binary variable
(0 -- Abaixo da Mediana; 1 -- Acima da Mediana)
median_age <- median(asma$`Idade (anos)`)
asma <- asma %>%
mutate(age_bin = ifelse(`Idade (anos)`>median_age,1,0))
summary(asma$age_bin)
?geom_bar
bar_NUTS <- ggplot() +
geom_bar(asma, mapping=aes(fill=`NUTS III`))
bar_NUTS
bar_NUTS <- ggplot() +
geom_bar(asma, mapping=aes(`NUTS III`, fill=`NUTS III`))
bar_NUTS
bar_NUTS <- ggplot() +
geom_bar(asma, mapping=aes(`NUTS III`, fill=`NUTS III`))+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
bar_NUTS
procedure_sum <- summary(asma$`Numero de Procedimentos`)
procedure_sum
hist_age <- hist(asma$`Idade (anos)`, breaks=90, right=F)
hist_procedure <- hist(asma$`Numero de Procedimentos`, breaks=50, right=F)
hist_procedure <- hist(asma$`Numero de Procedimentos`, breaks=50, right=F,
main="Histogram of number of procedures",
xlab="Number of procedures",
col="green")
hist_age <- hist(asma$`Idade (anos)`, breaks=90, right=F,
main="Histogram of participants age",
xlab="Age (years)",
col="#7dd67a")
#Quanti x Quanti
# No of procedures and intensive care days
plot(asma$`Numero de Procedimentos`, asma$`Dias de internamento`)
#Quanti x Quanti
# No of procedures and intensive care days
plot(asma$`Numero de Procedimentos`, asma$`Dias de internamento`,
main="Graphical representation of the correlation between hospitalization days and number of procedures",
xlab="Number of procedures",
ylab="Hospitalization days",
col="#d987e6")
#Quanti x Quanti
# No of procedures and intensive care days
plot(asma$`Numero de Procedimentos`, asma$`Dias de internamento`,
main="Graphical representation of the correlation between hospitalization days and number of procedures",
xlab="Number of procedures",
ylab="Hospitalization days",
col="#141d82")
# No of procedures and intensive care days
plot(asma$`Numero de Procedimentos`, asma$`Dias de internamento`,
main="Graphical representation of the correlation \nbetween hospitalization days and number of procedures",
xlab="Number of procedures",
ylab="Hospitalization days",
col="#141d82")
correlation <- cor.te
# No of procedures and intensive care days
plot(asma$`Numero de Procedimentos`, asma$`Dias de internamento`,
main="Graphical representation of the correlation \nbetween hospitalization days and number of procedures",
xlab="Number of procedures",
ylab="Hospitalization days",
col="#141d82")
#Quali x Quali --> Districts X Episode Type
cross_dist_epi <- xtabs(~asma$Distrito + asma$`Tipo Episodio`)
cross_dist_epi
correlation <- cor.test(asma$`Numero de Procedimentos`, asma$`Dias de internamento`)
correlation
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(ggplot2)
library(foreign)
library(qqplotr)
library(car)
library(emmeans)
library(DescTools)
library(FSA)
library(PMCMRplus)
NL_BD <- BD %>%
subset(NUTS_II %in% c("Norte", "Área Metropolitana de Lisboa"))
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(ggplot2)
library(foreign)
library(qqplotr)
library(car)
library(emmeans)
library(DescTools)
library(FSA)
library(PMCMRplus)
```
BD <- read.spss("TPC_3_Caracterizacao_Concelhos_Saude.sav", to.data.frame = TRUE)
NL_BD <- BD %>%
subset(NUTS_II %in% c("Norte", "Área Metropolitana de Lisboa"))
NL_BD <- BD %>%
filter(NUTS_II == "Norte" && NUTS_II == "Área Metropolitana de Lisboa")
View(NL_BD)
NL_BD <- BD %>%
subset(NUTS_II == "Norte" && NUTS_II == "Área Metropolitana de Lisboa")
View(NL_BD)
NL_BD <- BD %>%
subset(NUTS_II == "Norte")
View(NL_BD)
NL_BD <- BD %>%
subset((NUTS_II == "Norte") && (NUTS_II == "Área Metropolitana de Lisboa"))
View(NL_BD)
NL_BD <- BD %>%
subset((NUTS_II == "Norte") & (NUTS_II == "Área Metropolitana de Lisboa"))
View(NL_BD)
NL_BD <- BD %>%
subset(NUTS_II == "Norte" & NUTS_II == "Área Metropolitana de Lisboa")
View(NL_BD)
NL_BD <- BD %>%
subset(NUTS_II == "Norte" & NUTS_II == "Área Metropolitana de Lisboa")
NL_BD <- BD %>%
subset(NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa")
NL_BD1 <- BD[BD$NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa"]
#Files
BD <- read.spss("TPC_3_Caracterizacao_Concelhos_Saude.sav", to.data.frame = TRUE)
NL_BD1 <- BD[BD$NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa"]
View(BD)
NL_BD1 <- BD[BD$NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa"]
#Files
BD <- read.spss("TPC_3_Caracterizacao_Concelhos_Saude.sav", to.data.frame = TRUE)
NL_BD1 <- BD[BD$NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa"]
#########Exercise 1
# Compare region Norte and Lisbon according to number of doctors
# So what we have here is a quantitative variable (number of doctors) and a categorical variable (NUTS), meaning I want a t-test for independent samples
NL_BD <- BD %>%
subset(NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa")
NL_BD1 <- BD[BD$NUTS_II== "Norte" | NUTS_II== "Área Metropolitana de Lisboa"]
#Files
BD <- read.spss("TPC_3_Caracterizacao_Concelhos_Saude.sav", to.data.frame = TRUE) %>%
rename(nuts = NUTS_II)
NL_BD1 <- BD[BD$nuts== "Norte" | nuts== "Área Metropolitana de Lisboa"]
#Files
BD <- read.spss("TPC_3_Caracterizacao_Concelhos_Saude.sav", to.data.frame = TRUE) %>%
rename(nuts = NUTS_II)
NL_BD1 <- BD[BD$nuts== "Norte" | nuts== "Área Metropolitana de Lisboa"]
#########Exercise 1
# Compare region Norte and Lisbon according to number of doctors
# So what we have here is a quantitative variable (number of doctors) and a categorical variable (NUTS), meaning I want a t-test for independent samples
NL_BD <- BD %>%
subset(NUTS_II == "Norte", | NUTS_II == "Área Metropolitana de Lisboa",)
#########Exercise 1
# Compare region Norte and Lisbon according to number of doctors
# So what we have here is a quantitative variable (number of doctors) and a categorical variable (NUTS), meaning I want a t-test for independent samples
NL_BD <- BD %>%
subset(NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa",)
NL_BD1 <- BD[BD$nuts== "Norte" | nuts== "Área Metropolitana de Lisboa",]
#Files
BD <- read.spss("TPC_3_Caracterizacao_Concelhos_Saude.sav", to.data.frame = TRUE)
library(tidyverse)
library(ggplot2)
library(foreign)
library(qqplotr)
library(car)
library(emmeans)
library(DescTools)
library(FSA)
library(PMCMRplus)
#Files
BD <- read.spss("TPC_3_Caracterizacao_Concelhos_Saude.sav", to.data.frame = TRUE)
BD[BD$NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa",]
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(foreign)
library(qqplotr)
library(car)
library(emmeans)
library(DescTools)
library(FSA)
library(PMCMRplus)
NL_BD <- BD %>%
subset(NUTS_II == "Norte" | NUTS_II == "Área Metropolitana de Lisboa")
?subset
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("rlang")
install.packages("rlang")
plot(clust)
### Libraries
library(tidyverse)
library(foreign)
library(factoextra)
### Files
BD <- read.spss("BaseCovid.sav", to.data.frame = TRUE)
#subsetting bc i only want a few variables and standardizing
df <- BD %>%
select(c(country,total_cases_per_million_10, total_deaths_per_million_10, new_cases_per_million_10, new_deaths_per_million_10)) %>%
# next line to standardize our numeric variables
mutate_at(c("total_cases_per_million_10", "total_deaths_per_million_10", "new_cases_per_million_10", "new_deaths_per_million_10"), ~(scale(.) %>% as.vector)) %>%
# assigning the country column to rownames for the next steps (factoextra package)
column_to_rownames("country")
### Exercise 1
# Apply hierarchical and non hierarchical cluster analysis to the df and select the most adequate number of clusters
# Clustering is a technique in machine learning that attempts to find groups or clusters of observations within a dataset such that the observations within each cluster are quite similar to each other, while observations in different clusters are quite different from each other.
# .1 Hierarchical cluster analysis
# Proximity measure: Euclidean distance, Manhattan distance, Pearson correlation, etc.
# Aggregation criteria: Complete linkage, Single linkage, Ward’s minimum variance, etc.
# 1st Calculate the pairwise dissimilarity/correlation between each observation
dist.cor <- get_dist(df, method = "pearson") #proximity measure: Pearson correlation bc continuous variable
clust <- hclust(dist.cor, method = "single")
plot(clust)
fviz_dist(dist.cor)
# Cutting tree by no. of clusters
fit <- cutree(Hierar_cl, k = 3 )
abline(h = 110, col = "green")
# Cutting tree by no. of clusters
fit <- cutree(clust, k = 3 )
fit
table(fit)
rect.hclust(Hierar_cl, k = 3, border = "green")
rect.hclust(clust, k = 3, border = "green")
rect.hclust(clust, k = 4, border = "green")
# Cutting tree by no. of clusters
fit <- cutree(clust, k = 4 )
fit
table(fit)
rect.hclust(clust, k = 4, border = "green")
clust <- hclust(dist.cor, method = "single")
plot(clust)
abline(h = 110, col = "green")
# Cutting tree by no. of clusters
fit <- cutree(clust, k = 4 )
fit
table(fit)
rect.hclust(clust, k = 4, border = "green")
gap_stat <- clusGap(df, FUN = hcut, nstart = 25, K.max = 10, B = 50)
install.packages("cluster")
library(cluster)
gap_stat <- clusGap(df, FUN = hcut, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
install.packages("tidyr")
detach("package:tidyr", unload = TRUE)
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
### Libraries
library(tidyverse)
library(foreign)
library(factoextra)
library(cluster)
### Files
BD <- read.spss("BaseCovid.sav", to.data.frame = TRUE)
#subsetting bc i only want a few variables and standardizing
df <- BD %>%
select(c(country,total_cases_per_million_10, total_deaths_per_million_10, new_cases_per_million_10, new_deaths_per_million_10)) %>%
# next line to standardize our numeric variables
mutate_at(c("total_cases_per_million_10", "total_deaths_per_million_10", "new_cases_per_million_10", "new_deaths_per_million_10"), ~(scale(.) %>% as.vector)) %>%
# assigning the country column to rownames for the next steps (factoextra package)
column_to_rownames("country")
### Exercise 1
# Apply hierarchical and non hierarchical cluster analysis to the df and select the most adequate number of clusters
# Clustering is a technique in machine learning that attempts to find groups or clusters of observations within a dataset such that the observations within each cluster are quite similar to each other, while observations in different clusters are quite different from each other.
# .1 Hierarchical cluster analysis
# Proximity measure: Euclidean distance, Manhattan distance, Pearson correlation, etc.
# Aggregation criteria: Complete linkage, Single linkage, Ward’s minimum variance, etc.
# 1st Calculate the pairwise dissimilarity/correlation between each observation
dist.cor <- get_dist(df, method = "pearson") #proximity measure: Pearson correlation bc continuous variable
fviz_dist(dist.cor)
clust <- hclust(dist.cor, method = "single")
plot(clust)
### Libraries
library(tidyverse)
library(foreign)
library(factoextra)
library(cluster)
### Files
BD <- read.spss("BaseCovid.sav", to.data.frame = TRUE)
#subsetting bc i only want a few variables and standardizing
df <- BD %>%
select(c(country,total_cases_per_million_10, total_deaths_per_million_10, new_cases_per_million_10, new_deaths_per_million_10)) %>%
# next line to standardize our numeric variables
mutate_at(c("total_cases_per_million_10", "total_deaths_per_million_10", "new_cases_per_million_10", "new_deaths_per_million_10"), ~(scale(.) %>% as.vector)) %>%
# assigning the country column to rownames for the next steps (factoextra package)
column_to_rownames("country")
### Exercise 1
# Apply hierarchical and non hierarchical cluster analysis to the df and select the most adequate number of clusters
# Clustering is a technique in machine learning that attempts to find groups or clusters of observations within a dataset such that the observations within each cluster are quite similar to each other, while observations in different clusters are quite different from each other.
# .1 Hierarchical cluster analysis
# Proximity measure: Euclidean distance, Manhattan distance, Pearson correlation, etc.
# Aggregation criteria: Complete linkage, Single linkage, Ward’s minimum variance, etc.
# 1st Calculate the pairwise dissimilarity/correlation between each observation
dist.cor <- get_dist(df, method = "pearson") #proximity measure: Pearson correlation bc continuous variable
fviz_dist(dist.cor)
clust <- hclust(dist.cor, method = "single")
plot(clust)
### Libraries
library(tidyverse)
install.packages(c("ade4", "adehabitatHR", "adehabitatLT", "adehabitatMA", "blob", "bookdown", "cachem", "car", "checkmate", "classInt", "cli", "colorspace", "commonmark", "covr", "crul", "curl", "data.table", "deldir", "DEoptimR", "DescTools", "dplyr", "dtplyr", "e1071", "emmeans", "evaluate", "fansi", "fastmap", "fishmethods", "flexpolyline", "fontawesome", "Formula", "fs", "gargle", "gdata", "geojsonio", "geometries", "googledrive", "googlesheets4", "gtable", "haven", "hereR", "Hmisc", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "interp", "klaR", "knitr", "labelled", "later", "leaflet", "lme4", "markdown", "Matrix", "metafor", "modelr", "multcomp", "multcompView", "norm", "np", "openssl", "processx", "protolite", "ps", "psych", "qqconf", "quantreg", "raster", "Rcpp", "RcppTOML", "RCurl", "reticulate", "rgdal", "rgeos", "rlang", "rmarkdown", "Rmpfr", "robustbase", "s2", "sass", "servr", "sets", "sf", "sfheaders", "sp", "stringi", "styler", "svglite", "sys", "terra", "testthat", "TH.data", "tibble", "timechange", "tinytex", "TMB", "triebeard", "truncnorm", "tzdb", "units", "utf8", "V8", "vctrs", "VGAM", "viridis", "viridisLite", "vroom", "waldo", "wk", "xfun", "xml2", "yaml", "zip"))
library(tidyverse)
library(foreign)
library(factoextra)
library(cluster)
### Files
BD <- read.spss("BaseCovid.sav", to.data.frame = TRUE)
#subsetting bc i only want a few variables and standardizing
df <- BD %>%
select(c(country,total_cases_per_million_10, total_deaths_per_million_10, new_cases_per_million_10, new_deaths_per_million_10)) %>%
# next line to standardize our numeric variables
mutate_at(c("total_cases_per_million_10", "total_deaths_per_million_10", "new_cases_per_million_10", "new_deaths_per_million_10"), ~(scale(.) %>% as.vector)) %>%
# assigning the country column to rownames for the next steps (factoextra package)
column_to_rownames("country")
### Exercise 1
# Apply hierarchical and non hierarchical cluster analysis to the df and select the most adequate number of clusters
# Clustering is a technique in machine learning that attempts to find groups or clusters of observations within a dataset such that the observations within each cluster are quite similar to each other, while observations in different clusters are quite different from each other.
# .1 Hierarchical cluster analysis
# Proximity measure: Euclidean distance, Manhattan distance, Pearson correlation, etc.
# Aggregation criteria: Complete linkage, Single linkage, Ward’s minimum variance, etc.
# 1st Calculate the pairwise dissimilarity/correlation between each observation
dist.cor <- get_dist(df, method = "pearson") #proximity measure: Pearson correlation bc continuous variable
fviz_dist(dist.cor)
clust <- hclust(dist.cor, method = "single")
gap_stat <- clusGap(df, FUN = hcut, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
# Cutting tree by no. of clusters
fit <- cutree(clust, k = 5 )
fit
table(fit)
